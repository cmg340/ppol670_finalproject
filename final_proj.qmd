---
title: "Final Project - Predicting Health Indicators"
author: "Elena Spielmann, Patrick Jones, Leanne Chook, and Maeve Grady"
format: 
  html:
    code-fold: true
    self-contained: true
execute: 
  echo: true
  warning: false
  error: false
editor_options: 
  chunk_output_type: console
---
## Introduction 

Obesity has reached epidemic proportions in the United States, and affects people of all ages, socioeconomic backgrounds and ethnicities, which imposes substantial economic burdens in the form of productivity losses, strains to the healthcare system and costs. 

The prevalence of obesity in the United States was approximately 41.9% in 2017 to 2020, of that, the prevalence of severe obesity also increased to 9.2%. This increasing trend is worrying because obesity can lead to several other health conditions such as heart disease, strokes, type 2 diabetes, and certain types of cancers, all of which are the leading causes of preventable and premature deaths in the country. For these reasons, determining predictors of obesity is a public health priority. 

Furthermore, this increasing trend of obesity also has other implications on national security, especially as more individuals become ineligible for the military, therefore, significantly reducing military recruitment numbers. 

**Motivating question:**
What health, social, and economic indicators are most important in predicting obesity?

The main motivating question for this project was to examine obesity rates across the United States and find predictors that can help policymakers make effective decisions to help reduce obesity prevalence. Each of the selected data sets brings in different predictors to the model, covering health, social and economic aspects of obesity. This is relevant to the public policy sphere because the marrying of these different aspects are key to meaningful policy change and effective spending of government funds. Determining important predictors can help policymakers make effective decisions to help reduce obesity prevalence, which is a public health priority.

**Outline of project:**
First we will examine and clean up the available information from datasets downloaded from PLACES and the Food Access Repository Atlas. Then we will conduct exploratory data analysis (EDA) and geospatial analysis to guide our decision for the final models, and finally we create several predictive models to find the best model with highest predictive power. We will also determine what the most important variables for predicting obesity are for each model.

*Setup (loading packages)*

```{r}
#install.packages("httr")
library(httr)
library(sf)
#install.packages("ggiraph")
library(tmap)
library(dotenv)
library(here)
library(readxl)
library(dplyr)
library(tidyverse)
library(tidymodels)
library(themis)
library(rpart.plot)
library(vip)
library(lubridate)
library(rpart)
library(ranger)
library(ggplot2)
library(parsnip)
library(yardstick)
library(sf)
library(janitor) 
library(stringr)
library(RSocrata)
library(stringr)
library(mice)
library(sp)
library(tidyr)
library(caret)
library(patchwork)
library(tidycensus)
library(tigris)
options(tigris_use_cache = TRUE)
library(RColorBrewer)
library(ggiraph)

```

## Reading in Data using APIs
This endeavor used both the CDC's PLACES dataset and the USDA's FARA dataset. The team attempted to read each dataset in using API query's (attempts below) but ran into limitations in the APIs and in technical experise. In the case of the FARA dataset, the API available is hosted through ESRI as an ArcGIS REST service. This means that the query must be read in through an st_read()command, which made it very difficult to troubeleshoot query errors. There was limited documentation available for the FARA API. 

For the PLACES API, we successfully read in the data only to find that the API was not equipped to deliver data at the census tract level, only the county level. In both cases we opted instead to download data directly from the source websites at https://chronicdata.cdc.gov/browse?q=PLACES%202022 for PLACES and https://www.ers.usda.gov/data-products/food-access-research-atlas/download-the-data/ for the FARA dataset. After joining these two datasets, we also read in census tract shapefiles using the census API and library(tidycensus). 

```{r}
#| eval: false
#accessing FARA data through ArcGIS REST API
## to write this code I consulted this blog post: https://community.esri.com/t5/gis-blog/accessing-arcgis-rest-services-using-r/ba-p/898451

url <- parse_url("https://gis.ers.usda.gov/arcgis/rest/services")
url$path <- paste(url$path, "foodaccess2019/MapServer/0/query", sep = "/")
url$query <- list(returnGeometry = "true",
                  f = "geojson",
                  outFields = "*")
request <- build_url(url)

foodaccess <- st_read(request) ## this should create a full dataframe but is obviously not working right now.  


##using this api to try to figure out how the query should work:
##https://gis.ers.usda.gov/arcgis/rest/services/foodaccess2019/MapServer/0/query?where=&text=&objectIds=&time=&geometry=&geometryType=esriGeometryPolygon&inSR=&spatialRel=esriSpatialRelIntersects&distance=&units=esriSRUnit_Foot&relationParam=&outFields=*&returnGeometry=true&returnTrueCurves=false&maxAllowableOffset=&geometryPrecision=&outSR=&havingClause=&returnIdsOnly=false&returnCountOnly=false&orderByFields=&groupByFieldsForStatistics=&outStatistics=&returnZ=false&returnM=false&gdbVersion=&historicMoment=&returnDistinctValues=false&resultOffset=&resultRecordCount=&returnExtentOnly=false&datumTransformation=&parameterValues=&rangeValues=&quantizationParameters=&featureEncoding=esriDefault&f=html

```

```{r}
#| eval: false
#install.packages("RSocrata")
library(RSocrata) ## the Rsocrata package has to be loaded in after httr package for the above code to work 

##reading in api credentials
load_dot_env(here(".env"))
app_token <- Sys.getenv("PLACES_app_token")
user_name <- Sys.getenv("PLACES_username")
password <- Sys.getenv("PLACES_password")

#PLACES dataset

places <- read.socrata(
  "https://chronicdata.cdc.gov/resource/swc5-untb.json",
  app_token = paste(app_token),
  email     = paste(user_name),
  password  = paste(password)
)
```

## Combining the Datasets

**The Food Access Research Atlas (FARA)** provides a variety of food access measures for low income and low access census tracts. Food access measures use income, transportation, and distance from grocery stores and other food sellers to determine how accessible food is to residents of a given census tract. This dataset includes distinct measures of access for urban and rural populations.

**PLACES** is a collaboration between the CDC, CDC Foundation and the Robert wood Johnson Foundation. The dataset provides chronic disease measures at the county, census tract and ZCTA-level across the country.  This collaboration began in 2015 and contains both collected data and small area estimates dating back to 2016. 

These data sets can be combined with the census tracts.

```{r}
# load the FARA dataset 
fara <- read_excel("fara_2019.xlsx")

# clean the variable names 
fara <- clean_names(fara)

# load the PLACES dataset
places <- st_read("PLACES_ Local Data for Better Health, Census Tract Data 2022 release.geojson")%>% st_transform(value = 4326)

places <- places %>%
  rename(census_tract = locationid)

#The places dataset must be made tidy in order to properly merge it with FARA
#Column names will come from measureid, and values from data_value
#Crude and age adjusted values are distinguished by the data_value_type variable, the measureid
#variable does not distinguish between crude and age adjusted variables, we need to distinguish
#between the age adjusted and crude estimates before turning measureid values into columns
#start by simplifying data_value_type, crude is represented by C and adjusted by A
#When I got the right dataset, this step wasn't actually needed

#places_tidy <- places %>%
  #mutate(data_value_type = case_when(
    #data_value_type == "Crude prevalence" ~ "C",
    #data_value_type == "Age-adjusted prevalence" ~ "A"
  #))

#Next, add this to measureid to distinguish between crude and age-adjusted estimates
#places_tidy <- places_tidy %>%
  #mutate(measureid = str_c(measureid, data_value_type))

#creating tidy dataset
places_tidy <- places

#Filtering observations to 2020 only
places_tidy <- places %>%
  filter(year == 2020)

#There are a number of columns that are not necessary, they need to be dropped as well
places_tidy <- places_tidy %>%
  dplyr::select(-(c(statedesc, datasource, category, measure, data_value_unit,
          data_value_type, low_confidence_limit, high_confidence_limit,
          categoryid, datavaluetypeid, short_question_text, countyfips, 
          locationname, data_value_footnote, data_value_footnote_symbol,
          )))

#Finally, we can pivot this dataset to wide format
places_tidy <- places_tidy %>%
  pivot_wider(names_from = "measureid",
              values_from = "data_value")

# merge the data frames by census tract
#swapped places and fara so that the combined dataset only has census tracts that are in fara
combined <- right_join(places_tidy, fara,
                      by = "census_tract")

# Read in the shapefile - opting for tidy census here
load_dot_env(here(".env"))


census_api_key("census_api_key", install = T, overwrite=TRUE)

options(tigris_use_cache = TRUE)

allstates <- c(state.abb)
allstates

census <- get_acs(state = allstates ,
                  geography = "tract", 
                  variables =  "B19013_001",
                  geometry = TRUE,
                  year = 2019)%>%
  rename(census_tract = GEOID)%>%
  st_transform(crs = st_crs(4326))
  


#binding census shapefile to this dataset
combined_nonsf <- combined %>% st_transform(crs = st_crs(4326))
combined_census <- st_join(census, combined_nonsf, join = st_intersects)



```

## Exploratory Data Analysis

Use EDA to to understand the distribution of the variables and identify patterns or relationships. Use things like scatter plots or correlation matrices to visualize the relationship between obesity prevalence and other factors like food access, income, or education

```{r}
glimpse(combined)

#A ton of our numeric variables are stored as character variables, they need to be converted to numeric variables
to_convert <- colnames(select_if(combined, is.character))
to_convert <- to_convert[!to_convert %in% c("census_tract", "countyname", "year", "stateabbr", "geometry")]
to_convert <- unlist(to_convert)
combined <- combined %>%
  mutate_at(to_convert, as.numeric)

#some of these numerics need to be converted to factors
factors <- c("urban", "group_quarters_flag", "lila_tracts_1and10", "lila_tracts_half_and10",
            "lila_tracts_vehicle", "hunv_flag", "low_income_tracts",
             "la1and20", "la_tracts_half", "la_tracts1", "la_tracts10",
             "la_tracts20", "la_tracts_vehicle_20")
combined <- combined %>%
  mutate_at(factors, as.factor)

eda_point <- function(data, x, y, fill){
  
  ggplot(data = data, 
       aes(x = {{ x }},
           y = {{ y }})) +
  geom_point(aes(fill = {{ fill }}),
             color = "white", 
             shape = 21) 
}
combined %>%
  st_transform(4326)


eda_geo <- function(data, fill){
  
  ggplot(data = data) +
  geom_sf(aes(fill = {{ fill }})) +
  theme_void() 
}

#point plot to compare obesity prevalence between urban and rural areas
eda_point(combined, poverty_rate, OBESITY, urban)

#boxplot to compare the distribution of obesity prevalence between urban and rural areas
ggplot(combined, aes(x = urban, y = OBESITY)) +
  geom_boxplot() +
  labs(x = "Urban/Rural", y = "Obesity Prevalence")

#While the average obesity rate is higher in rural areas, urban areas have higher variability of of data.

#chloropleth map of obesity - need to set the data
eda_geo(combined, OBESITY)

#Exploration by state.This highlights the importance of exploring these data by
#census tract instead of state. Exploring by state would be misleading.

# Calculate summary statistics by state
summary_stats <- combined %>%
  group_by(stateabbr) %>%
  summarize(mean_obesity = mean(OBESITY, na.rm = TRUE),
            median_income = median(median_family_income, na.rm = TRUE),
            sd_food_access = sd(la1and10, na.rm = TRUE))


head(summary_stats)

# Plot mean obesity by state
ggplot(summary_stats, aes(x = stateabbr, y = mean_obesity)) +
  geom_bar(stat = "identity") +
  labs(x = "State", y = "Mean Obesity") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
#Southern states have the highest rates of obesity. HI has the lowest rate.

# Plot median income by state
ggplot(summary_stats, aes(x = stateabbr, y = median_income)) +
  geom_bar(stat = "identity") +
  labs(x = "State", y = "Median Income") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
# DC has the highest median income and MS has the lowest

# Plot standard deviation of food access by state
ggplot(summary_stats, aes(x = stateabbr, y = sd_food_access)) +
  geom_bar(stat = "identity") +
  labs(x = "State", y = "Standard Deviation of Food Access") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

#most states have a high degree of variability which suggests that
#food access varies widely across census tracts within a state

```



```{r}
glimpse(combined_census)
combined_census <- combined_census %>% clean_names()

#binning obesity rates and creating text to work with
combined_census <- combined_census %>%
  mutate(obesity_num = as.numeric(obesity),
         obesity_bin = cut(obesity_num, breaks = 10),
         maptext = paste0("State: ", as.character(stateabbr), "\n",
                          "Tract: ", as.character(census_tract_x), "\n",
                         "Obesity rate: ", as.character(obesity), "\n",
                         "Rate of current smokers: ", as.character(csmoking), "\n",
                         "Rate of teeth lost: ", as.character(teethlost), "\n",
                         "Median family income: ", as.character(median_family_income)))

  
obesity_tracts <-  ggplot()+
  geom_sf(data = combined_census, 
          aes(fill = obesity_bin),
          lwd = 0,
          color = NA)+
  scale_fill_brewer(palette = "RdYlGn",direction  = -1,  aesthetics = "fill")+
  labs(title = "Adult obesity rate by census tract in the US")+
  coord_sf(xlim=c(-160, -64),ylim=c(18,72), crs = 4326) +
  theme_void()

obesity_tracts
```

```{r}
#| eval: false
#ignoring this block for now since it doesn't work yet
#interactive map attempt - this isn't working yet
obesity_tracts_int <-  ggplot()+
  geom_sf_interactive(data = combined_census, 
          aes(fill = obesity_bin,
          data_id = maptext,
          tooltip = maptext),
          lwd = 0,
          color = NA)+
  scale_fill_brewer(palette = "RdYlGn",direction  = -1,  aesthetics = "fill")+
  labs(title = "Adult obesity rate by census tract in the US")+
  coord_sf(xlim=c(-160, -64),ylim=c(18,72), crs = 4326) +
  theme_void()

girafe(ggobj = obesity_tracts_int) %>%
  girafe_options(opts_hover(css = "fill:blue;"), opts_sizing(rescale = TRUE, width = 1))



install.packages("mapview")
library(mapview)
combined_census %>% select(name, obesity_bin, median_family_income, csmoking, teethlost) %>%
  mapview(zcol = "obesity_bin",
          map.types = "Esri.NatGeoWorldMap")


```


## (Supervised) Machine Learning

*Setting up the testing environment*

```{r}


# separate geometry column into longitude and latitude and prepare it for recipe 
combinedsmall <- combined %>%
  select(census_tract, COPD, OBESITY, STROKE, DEPRESSION, LPA, CASTHMA, TEETHLOST, ARTHRITIS, DIABETES, BINGE, SLEEP, ACCESS2, PHLTH, DENTAL, MHLTH, CANCER, CHD, GHLTH, CHECKUP, CSMOKING, CERVICAL, KIDNEY, COLON_SCREEN, COREW, urban, median_family_income, la1and10, lalowi1share, lakids1share, laseniors1share, lahunv1share)


combinedsep <- combinedsmall %>%
  mutate(longitude = st_coordinates(geometry)[, "X"],
         latitude = st_coordinates(geometry)[, "Y"]) 

# to remove the geometry column from dataframe 
combinedsep <- st_drop_geometry(combinedsep)

# convert all variables to numeric
combinedsep$urban <- as.numeric(as.character(combinedsep$urban))

# set seed
set.seed(20230507)

# split the data into training and testing sets 
obesity_split <- initial_split(data = combinedsep, 
                               prop = 0.8)

obesity_train <- training(x = obesity_split)
obesity_test <- testing(x = obesity_split)

# set up v-fold cross validation 
folds <- vfold_cv(data = obesity_train, v = 5, repeats = 1)

# create a recipe (need to look at what needs to be added)
obesity_rec <- recipe(OBESITY ~., data = obesity_train) %>%
  step_other(census_tract) %>%
  step_naomit(all_predictors()) %>%
  step_center(all_numeric_predictors()) %>%
  step_scale(all_numeric_predictors()) %>%
  step_dummy(census_tract)


```

**Linear Regression**
This is a simple and widely-used statistical model for predicting a continuous outcome based on one or more predictor variables. The goal is to find a linear relationship between the outcome and predictors, which can be used to make predictions.

```{r}

# create a linear regression model using the "lm" package as the engine
lm_mod <- linear_reg() %>%
  set_engine("lm")

# create a workflow with the recipe and linear regression model you've created
lm_wf <- workflow() %>%
  add_recipe(obesity_rec) %>%
  add_model(lm_mod) 

# fit the model by piping your workflow
lm_cv <- lm_wf %>%
  fit_resamples(resamples = folds)

# select the best model based on the "rmse" metric
lm_best <- lm_cv %>%
  select_best("rmse")

# use the finalize_workflow() function with your workflow and the best model 
# to update (or "finalize") your workflow by modifying the line below
lm_final <- finalize_workflow(
  lm_wf,
  parameters = lm_best
)

# fit to the training data and extract coefficients
lm_coefs <- lm_final %>%
  fit(data = obesity_train) %>%
  extract_fit_parsnip() %>%
  vi(lambda = lasso_best$penalty)

```

**LASSO Model**
This is a linear regression model with a regularization term added to the objective function, which helps to prevent overfitting and improve generalization performance. The LASSO penalty shrinks some of the regression coefficients towards zero, effectively selecting a subset of the most important predictors for the outcome.
```{r}
# create a tuning grid for lasso regularization, varying the regularization penalty
lasso_grid <- grid_regular(penalty(), levels = 10)

# create a linear_regression model so that you can tune the penalty parameter
# set the mixture parameter to 1 and use "glmnet" for the engine
lasso_mod <- linear_reg(
  penalty = tune(), 
  mixture = 1
) %>%
  set_engine("glmnet")

# create a workflow using your updated linear regression model you just created and the same recipe
# you defined above
lasso_wf <- workflow() %>%
  add_recipe(obesity_rec) %>%
  add_model(lasso_mod) 

# perform hyperparameter tuning using the lasso_grid and the 
# cross_validation folds you created above by modifying the line below
lasso_cv <- lasso_wf %>%
  tune_grid(
    resamples = folds,
    grid = lasso_grid
  )

# select the best model based on the "rmse" metric
lasso_best <- lasso_cv %>%
  select_best(metric = "rmse")

# use the finalize_workflow() function with your lasso workflow and the best model 
# to update (or "finalize") your workflow by modifying the line below
lasso_final <- finalize_workflow(
  lasso_wf,
  parameters = lasso_best
)

# fit to the training data and extract coefficients
lasso_coefs <- lasso_final %>%
  fit(data = obesity_train) %>%
  extract_fit_parsnip() %>%
  vi(lambda = lasso_best$penalty) 

```

**Ridge Model**
This is also a linear regression model with a regularization term, but instead of selecting a subset of predictors, it shrinks all of the regression coefficients towards zero. This can help to reduce the impact of multicollinearity among the predictors.
```{r}

# create a tuning grid for ridge regularization, varying the regularization penalty
ridge_grid <- grid_regular(penalty(), levels = 10)

# create a linear_regression model so that you can tune the penalty parameter
ridge_mod <- linear_reg(
  penalty = tune(), 
  mixture = 0
) %>%
  set_engine("glmnet")

# create a ridge workflow using your updated linear regression model you just created and 
# the same recipe you defined above
ridge_wf <- workflow() %>%
  add_recipe(obesity_rec) %>%
  add_model(ridge_mod)

# perform hyperparameter tuning using the on your ridge hyperparameter grid and
# cross_validation folds you created above by modifying the line below
# use the tune_grid() function
ridge_cv <- ridge_wf %>%
  tune_grid(
    resamples = folds,
    grid = ridge_grid
  )

# select the best model based on the "rmse" metric
ridge_best <- ridge_cv %>%
  select_best(metric = "rmse")

# use the finalize_workflow() function with your ridge workflow and the best model 
# to update (or "finalize") your workflow
ridge_final <- finalize_workflow(
  ridge_wf,
  parameters = ridge_best
)

# fit the final ridge model to the full training data and extract coefficients
# by updating the line below
ridge_coefs <- ridge_final %>%
  fit(data = obesity_train) %>%
  extract_fit_parsnip() %>%
  vi(lambda = ridge_best$penalty) 

```

**Elastic Net**
This is a combination of LASSO and ridge regression, with both penalties included in the objective function. This can help to balance the benefits of variable selection and coefficient shrinkage, and is useful when the data contains many correlated predictors.
```{r}
# create a tuning grid for elastic net regularization, varying the regularization penalty
elastic_net_grid <- grid_regular(penalty(), levels = 10)

# create a linear_regression model so that you can tune the penalty parameter
# and use "glmnet" for the engine. If you set mixture = 1 for lasso regression above,
# and mixture = 0 for ridge regression, what should you set mixture equal to for elastic net?
elastic_net_mod <- linear_reg(
  penalty = tune(), 
  mixture = 0.5) %>%
  set_engine("glmnet")

# create an elastic net workflow using your updated linear regression model you just created and 
# the same recipe you defined above
elastic_net_wf <- workflow() %>%
  add_recipe(obesity_rec) %>%
  add_model(elastic_net_mod)

# perform hyperparameter tuning using the on your elastic net hyperparameter grid and
# cross_validation folds you created above by modifying the line below
elastic_net_cv <- elastic_net_wf %>%
  tune_grid(
    resamples = folds,
    grid = elastic_net_grid)

# select the best model based on the "rmse" metric
elastic_net_best <- elastic_net_cv %>%
  select_best(metric = "rmse")

# use the finalize_workflow() function with your elastic net workflow and the best model 
# to update (or "finalize") your workflow
elastic_net_final <- finalize_workflow(
  elastic_net_wf,
  parameters = elastic_net_best)

# fit the final elastic net model to the full training data and extract coefficients
# by updating the line below
elastic_net_coefs <- elastic_net_final %>%
  fit(data = obesity_train) %>%
  extract_fit_parsnip() %>%
  vi(lambda = elastic_net_best$penalty)

```

## Compare Models

```{r}
# the models are comparable for prediction accuracy
bind_rows(
  `lm` = show_best(lm_cv, metric = "rmse", n = 1),
  `LASSO` = show_best(lasso_cv, metric = "rmse", n = 1),
  `ridge` = show_best(ridge_cv, metric = "rmse",n = 1),
  `enet` = show_best(elastic_net_cv, metric = "rmse", n = 1),
  .id = "model"
)

all_coefs <- bind_rows(
  `lm` = lm_coefs,
  `LASSO` = lasso_coefs,
  `ridge` = ridge_coefs,
  `enet` = elastic_net_coefs,
  .id = "model"
) 

all_coefs %>%
  group_by(model) %>%
  slice_max(Importance, n = 10) %>%
  ggplot(aes(Importance, Variable, fill = model)) +
  geom_col(position = "dodge")

all_coefs %>%
  filter(model != "lm") %>%
  group_by(model) %>%
  slice_max(Importance, n = 10) %>%
  ggplot(aes(Importance, Variable, fill = model)) +
  geom_col(position = "dodge")


# compare the regularized coefficients to the lm coefficients for all three models
plot1 <- left_join(
  rename(lm_coefs, lm = Importance),
  rename(lasso_coefs, LASSO = Importance),
  by = "Variable"
) %>%
  ggplot(aes(lm, LASSO)) +
  geom_point(alpha = 0.3)

plot2 <- left_join(
  rename(lm_coefs, lm = Importance),
  rename(ridge_coefs, ridge = Importance),
  by = "Variable"
) %>%
  ggplot(aes(lm, ridge)) +
  geom_point(alpha = 0.3)

plot3 <- left_join(
  rename(lm_coefs, lm = Importance),
  rename(elastic_net_coefs, enet = Importance),
  by = "Variable") %>%
  ggplot(aes(lm, enet)) +
  geom_point(alpha = 0.3)

plot1 + plot2 + plot3
```

**Decision Tree Model**

```{r}
# create a model
tree_mod <- 
  decision_tree() %>%
  set_engine(engine = "rpart") %>%
  set_mode(mode = "regression")

# create a workflow
tree_wf <- workflow() %>%
  add_recipe(obesity_rec) %>%
  add_model(tree_mod)



# fit model to the training set 
tree_fit <- tree_wf %>%
  fit(data = obesity_train)

# create a tree 
rpart.plot::rpart.plot(x = tree_fit$fit$fit$fit, roundint = FALSE)


#make predictions on train data
predictions <- bind_cols(
  obesity_train,
  predict(object = tree_fit, new_data = obesity_train)
)

pred_tree <- predict(object = tree_fit, new_data = obesity_train) 

#evaluating model
predictions <- predictions %>% drop_na(OBESITY, .pred) %>% mutate(
  error = .pred - OBESITY,
  sqerror = error^2
)

mse_tree <- mean(predictions$sqerror)
mse_tree


# variable importance

tree_fit %>% 
  extract_fit_parsnip() %>% 
  vip(num_features = 10)

#tuning tree
gridval <- 10

tree_res <- tree_wf %>%
  tune_grid(resample = folds, grid = gridval,
            control=control_grid(save_pred = TRUE))



tree_best <- tree_res %>%
  select_best(metric = "rmse")


tree_tuned <- tree_wf %>%
  finalize_workflow(parameters = tree_best)


tree_final  <-  fit( tree_tuned, obesity_train)


# variable importance

tree_final %>% 
  extract_fit_parsnip() %>% 
  vip(num_features = 10)

#predictions with tuned model

newpredictions <- bind_cols(
  obesity_test,
  predict(tree_final, obesity_test)
)


#evaluating model
newpredictions <- newpredictions %>% drop_na(OBESITY, .pred) %>% mutate(
  error = .pred - OBESITY,
  sqerror = error^2
)

mse_prunedtree <- mean(newpredictions$sqerror)
mse_prunedtree


#was having trouble testing this model - after the above the RMSE is the same, below is my first attempt to tune the model
```

```{r}

#| eval: false
# first attempt to tune tree -- did not go well
fit.tree = rpart(OBESITY ~ ., data=obesity_train, method = "anova", cp=0.00009)
fit.tree

printcp(fit.tree)

bestcp <- fit.tree$cptable[which.min(fit.tree$cptable[,"xerror"]),"CP"]
bestcp

#best cp has xerror of  0.28414

#prune the tree
pruned.tree <- prune(fit.tree, cp = bestcp)

#plot the pruned tree
rpart.plot(pruned.tree)


# variable importance in pruned tree
pruned.tree$variable.importance

#predictions with pruned tree

newpredictions <- bind_cols(
  obesity_test,
  predict( pruned.tree, nobesity_test)
)

#evaluating model
newpredictions <- newpredictions %>% drop_na(OBESITY, .pred) %>% mutate(
  error = .pred - OBESITY,
  sqerror = error^2
)

mse_prunedtree <- mean(newpredictions$sqerror)
mse_prunedtree


```

## Results

**Best Models**
In order to pick the best model, we consider the RMSE as the metric used for evaluation, the mean value of the metric across the folds, and the standard error of the metric. Generally, we want to choose the model that has the lowest value of the metric, as this indicates better performance on the test data.

The RMSE values for lm, LASSO, and enet are all the same at 2.55. However, the ridge model has a slightly higher rmse of 2.69. This suggests that the lm, LASSO, and enet models may be better choices than the ridge model.

Additionally, we consider the standard error of the metric. The standard error gives an estimate of the precision of the mean estimate, with a lower value indicating more precision. In our case, we can see that the standard errors for all models are quite small, indicating that the mean estimates are likely quite precise.

**Most Important Variables**
The two most important variables for each model are consistently diabetes and arthritis across the board with regard to obesity. Specifically, people with diabetes and arthritis may be more likely to develop obesity.

Evaluating discrepancies: If a variable has a high importance in one model, but not in other models, it means that the other models are able to achieve comparable prediction accuracy without relying heavily on that particular variable. In this case, the variable BINGE is highly important in the lm model but not in LASSO, ridge, and enet models. This suggests that BINGE may be correlated with other predictors, and the regularization techniques in LASSO, ridge, and enet models are able to effectively deal with this multicollinearity by shrinking the coefficient of BINGE to zero or close to zero. Therefore, it is likely that BINGE does not contribute much additional information in predicting obesity after accounting for the other predictors in the LASSO, ridge, and enet models. However, the lm model may be overfitting to BINGE due to the absence of regularization, which could explain why it is highly important in that model.


