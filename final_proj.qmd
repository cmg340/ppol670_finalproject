---
title: "Final Project - Predicting Health Indicators"
author: "Elena Spielmann, Patrick Jones, Leanne Chook, and Maeve Grady"
format: 
  html:
    code-fold: true
    self-contained: true
execute: 
  echo: true
  warning: false
  error: false
editor_options: 
  chunk_output_type: console
---
## Introduction 

*Motivating question:*


*Outline of project:*


## Setup (loading packages)
```{r}

install.packages("httr")
library(httr)
library(sf)
#install.packages("tmap")
library(tmap)
library(dotenv)
library(here)
library(readxl)
library(dplyr)
library(tidyverse)
library(tidymodels)
library(themis)
library(rpart.plot)
library(vip)
library(lubridate)
library(rpart)
library(ranger)
library(ggplot2)
library(parsnip)
library(yardstick)
library(sf)
library(janitor) 

```

## Reading in Data using APIs

```{r}
#accessing FARA data through ArcGIS REST API
## to write this code I consulted this blog post: https://community.esri.com/t5/gis-blog/accessing-arcgis-rest-services-using-r/ba-p/898451

url <- parse_url("https://gis.ers.usda.gov/arcgis/rest/services")
url$path <- paste(url$path, "foodaccess2019/MapServer/0/query", sep = "/")
url$query <- list(returnGeometry = "true",
                  f = "geojson",
                  outFields = "*")
request <- build_url(url)

foodaccess <- st_read(request) ## this should create a full dataframe but is obviously not working right now.  


##using this api to try to figure out how the query should work:
##https://gis.ers.usda.gov/arcgis/rest/services/foodaccess2019/MapServer/0/query?where=&text=&objectIds=&time=&geometry=&geometryType=esriGeometryPolygon&inSR=&spatialRel=esriSpatialRelIntersects&distance=&units=esriSRUnit_Foot&relationParam=&outFields=*&returnGeometry=true&returnTrueCurves=false&maxAllowableOffset=&geometryPrecision=&outSR=&havingClause=&returnIdsOnly=false&returnCountOnly=false&orderByFields=&groupByFieldsForStatistics=&outStatistics=&returnZ=false&returnM=false&gdbVersion=&historicMoment=&returnDistinctValues=false&resultOffset=&resultRecordCount=&returnExtentOnly=false&datumTransformation=&parameterValues=&rangeValues=&quantizationParameters=&featureEncoding=esriDefault&f=html

```

```{r}
#install.packages("RSocrata")
library(RSocrata) ## the Rsocrata package has to be loaded in after httr package for the above code to work 

##reading in api credentials
load_dot_env(here(".env"))
app_token <- Sys.getenv("PLACES_app_token")
user_name <- Sys.getenv("PLACES_username")
password <- Sys.getenv("PLACES_password")


#PLACES dataset

places <- read.socrata(
  "https://chronicdata.cdc.gov/resource/swc5-untb.json",
  app_token = paste(app_token),
  email     = paste(user_name),
  password  = paste(password)
)
```

## Combining the Datasets

**The Food Access Research Atlas (FARA)** provides a variety of food access measures for low income and low access census tracts. Food access measures use income, transportation, and distance from grocery stores and other food sellers to determine how accessible food is to residents of a given census tract. This dataset includes distinct measures of access for urban and rural populations.

(rewrite this)
**PLACES** is an expansion of the original 500 Cities Project that began in 2015. The original project was launched by the Centers for Disease Control and Prevention (CDC) in partnership with the Robert Wood Johnson Foundation (RWJF) and CDC Foundation. In 2018, this partnership was extended through 2020. In 2020, the project expanded to provide small area estimates (SAE) for counties, places, census tracts, and ZIP Code Tabulation Areas (ZCTA) across the entire United States.

```{r}
# load the FARA dataset 
fara <- read_excel("fara_2019.xlsx")

# clean the variable names 
fara <- clean_names(fara)

# load the PLACES dataset
places <- st_read("PLACES_ Local Data for Better Health, Census Tract Data 2022 release.geojson")

places <- places %>%
  rename(census_tract = locationid)

# merge the data frames by census tract 
combined <- left_join(places, fara, 
                      by = "census_tract") 

# clean and prepocess dataset - remove missing values, outliers or irrelevant variables that may affect the anlaysis 

```

## Exploratory Data Analysis

Use EDA to to understand the distribution of the variables and identify patterns or relationships. Use things like scatter plots or correlation matrices to visualise the relationship between obesity prevalence and other factors like food access, income, or education

```{r}

```

## Machine Learning

*Setting up the testing environment*

```{r}
set.seed(20230507)

# split the data into training and testing sets 
obesity_split <- initial_split(data = combined, 
                               prop - 0.8)

obesity_train <- training(x = obesity_split)
obesity_test <- testing(x = obesity_split)

# set up v-fold cross validation 
folds <- vfold_cv(data = obesity_train, v = 10, repeats = 1)

```

**Linear Regression (or any other) Model**

```{r}

# create model
lm_mod <- linear_reg() %>%
  set_engine("lm") %>%
  set_mode(mode = "regression")

# set up workflow 
lm_wf <- workflow() %>%
  add_recipe(obesity_rec) %>%
  add_model(lm_mod)

# use resamples 
lm_cv <- lm_wf %>%
  fit_resamples(resamples = folds,
                metrics = metric_set(rmse, mae))

# collect metrics and find the best model
lm_best <- lm_cv %>%
  select_best(metric = "rmse")

lm_final <- lm_wf %>%
  finalize_workflow(parameters = lm_best)

collect_metrics(lm_cv, summarize = TRUE)

# fit the model
lm_fit <- lm_final %>%
  fit(obesity_train)

# evaluate its performance using MSE or accuracy

collect_metrics(lm_cv, summarize = FALSE) %>%
  filter(.metric == "rmse") %>%
  ggplot(mapping = aes(x = id, y = .estimate, group = .estimator, label = round(.estimate, digits = 2))) +
  geom_line() +
  geom_point() +
  geom_label(nudge_y = -500) +
  scale_y_continuous(limits = c(10000, 17500)) +
  labs(title = "Obesity: Linear Regression Model (RMSE Across 10 Folds)", 
       y = "Predicted RMSE",
       x = "Fold Number") +
  theme_minimal()

```

**KNN Model**

```{r}
knn_mod <- nearest_neighbor(neighbors = tune()) %>%
  set_engine(engine = "kknn") %>%
  set_mode(mode = "regression")

# set up workflow
knn_workflow <- 
  workflow() %>%
  add_model(spec = knn_mod) %>%
  add_recipe(recipe = obesity_rec)

# create a tuning grid 
knn_grid <- grid_regular(neighbors(range = c(1, 15)), levels = 8)

# fitting model to the training data 
knn_res <- 
  knn_workflow %>%
  tune_grid(resamples = folds,
            grid = knn_grid,
            control = control_grid(save_pred = TRUE),
            metrics = metric_set(rmse, mae))

# collecting the metrics and determining the best model
knn_best <- knn_res %>%
  select_best(metric = "rmse")

# finalize workflow 
knn_final <- knn_workflow %>%
  finalize_workflow(parameters = knn_best)

# fit model 
knn_fit <- knn_final %>%
  fit(obesity_train)

knn_fit_rs <- knn_final %>%
  fit_resamples(resamples = folds)

# evaluate the model
collect_metrics(knn_res, summarize = FALSE) %>%
  filter(.metric == "rmse") %>%
  ggplot(mapping = aes(x = id, y = .estimate, group = .estimator, label = round(.estimate, digits = 2))) +
  geom_line() +
  geom_point() +
  geom_label(nudge_y = -500) +
  scale_y_continuous(limits = c(10000, 17500)) +
  labs(title = "Obesity: KNN Model (RMSE Across 10 Folds)", 
       y = "Predicted RMSE",
       x = "Fold Number") +
  theme_minimal()


```

**Decision Tree Model**

```{r}
# create a recipe
obesity_rec <- recipe(formula = , 
                      data = obesity_train)

# create a model
tree_mod <- 
  decision_tree() %>%
  set_engine(engine = "rpart") %>%
  set_mode(mode = "classification")

# create a workflow
tree_wf <- workflow() %>%
  add_recipe(obesity_rec) %>%
  add_model(tree_mod)

# resampling 
tree_cv <- tree_wf %>%
  fit_resamples(resamples = folds)

# use RMSE to choose the best model 
tree_best <- tree_cv %>%
  select_best(metric = "rmse")

# finalise workflow 
tree_final <- tree_wf %>%
  finalize_workflow(parameters = tree_best)

# fit model to the training set 
tree_fit <- tree_wf %>%
  fit(data = obesity_train)

# create a tree 
rpart.plot::rpart.plot(x = obesity_fit$fit$fit$fit, roundint = FALSE)


```

*Evaluate Model*

```{r}
# making predictions on the test dataset
predictions <- bind_cols(
  obesity_test,
  predict(object = obesity_fit, new_data = obesity_test),
  predict(object = obesity_fit, new_data = obesity_test, type = "prob")
)

#comparing tree predictions to true values
conf_mat(data = predictions, 
         truth = grade,
         estimate = .pred_class)

#calculating accuracy, recall, and precision
accuracy <- accuracy(data = predictions,
                     truth = grade,
                     estimate = .pred_class)


precision <- yardstick::precision(data = predictions,
                                  truth = grade,
                                  estimate = .pred_class)

recall <- yardstick::recall(data = predictions,
                            truth = grade,
                            estimate = .pred_class)

print(c("the model accuracy is:", round(accuracy$.estimate, digits = 3)))
print(c("the model precision is:", round(precision$.estimate, digits = 3)))

print(c("the model recall is:", round(recall$.estimate, digits = 3)))


# variable importance

tree_fit %>% 
  extract_fit_parsnip() %>% 
  vip(num_features = 10)

```

## Final Results 


## Conclusion 